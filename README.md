# ReasoningMemoryAdapter
Uses a graph attention layer to augment LORA also uses special memory embeddings injected via a memory token
